{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5e0f8f",
   "metadata": {},
   "source": [
    "# ANNS Experiment Notebook\n",
    "\n",
    "This notebook is designed to run the segmented cosine similarity ANNS experiments on Kaggle.\n",
    "\n",
    "## Instructions\n",
    "1. **Dataset**: This notebook expects the dataset (e.g., `coco-i2i-512-angular.hdf5`) to be available. \n",
    "   - You can upload it to Kaggle Datasets and attach it to this notebook.\n",
    "   - Or use the download cell below to fetch it from `ann-benchmarks.com` if available.\n",
    "2. **Configuration**: Adjust the variables in the \"Configuration (Arguments)\" cell to change experiment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages if not present\n",
    "!pip install h5py tqdm torch pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de739027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "\n",
    "# Dataset Setup\n",
    "# This cell handles finding the dataset either from Kaggle Input or via download\n",
    "# and placing it where the code expects it (./COCO-I2I/...).\n",
    "\n",
    "dataset_name = \"COCO-I2I\"\n",
    "dataset_filename = \"coco-i2i-512-angular.hdf5\"\n",
    "expected_dir = f\"./{dataset_name}\"\n",
    "expected_path = f\"{expected_dir}/{dataset_filename}\"\n",
    "\n",
    "# Create expected directory\n",
    "os.makedirs(expected_dir, exist_ok=True)\n",
    "\n",
    "# 1. Search in Kaggle Input (Recursively)\n",
    "# If you attached a dataset to this kernel, it will be in /kaggle/input\n",
    "found_in_input = False\n",
    "if os.path.exists(\"/kaggle/input\"):\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        if dataset_filename in files:\n",
    "            source_path = os.path.join(root, dataset_filename)\n",
    "            print(f\"Found dataset in Kaggle input: {source_path}\")\n",
    "            \n",
    "            # Remove existing file if it's there (to avoid confusion with partial downloads)\n",
    "            if os.path.exists(expected_path):\n",
    "                if not h5py.is_hdf5(expected_path):\n",
    "                    print(\"Removing existing invalid file.\")\n",
    "                    os.remove(expected_path)\n",
    "                else: \n",
    "                    print(\"Existing valid file found, keeping it.\")\n",
    "                    found_in_input = True\n",
    "                    break\n",
    "\n",
    "            # Symlink or Copy\n",
    "            try:\n",
    "                if os.path.exists(expected_path):\n",
    "                     os.remove(expected_path)\n",
    "                os.symlink(source_path, expected_path)\n",
    "                print(f\"Symlinked to {expected_path}\")\n",
    "            except OSError:\n",
    "                shutil.copy(source_path, expected_path)\n",
    "                print(f\"Copied to {expected_path}\")\n",
    "            \n",
    "            found_in_input = True\n",
    "            break\n",
    "\n",
    "# 2. Download if not found in input and not locally valid\n",
    "if not found_in_input:\n",
    "    if os.path.exists(expected_path) and h5py.is_hdf5(expected_path):\n",
    "        print(\"Valid local file found.\")\n",
    "    else:\n",
    "        print(\"Dataset not found in input or invalid. Attempting download...\")\n",
    "        # Clean up invalid file\n",
    "        if os.path.exists(expected_path):\n",
    "            os.remove(expected_path)\n",
    "            \n",
    "        url = f\"http://ann-benchmarks.com/{dataset_filename}\"\n",
    "        print(f\"Downloading from {url}...\")\n",
    "        # Use -q (quiet), -c (continue), --show-progress\n",
    "        !wget -q --show-progress -c -O {expected_path} {url}\n",
    "        print(\"Download finished.\")\n",
    "\n",
    "# 3. Validation Check\n",
    "if os.path.exists(expected_path):\n",
    "    if h5py.is_hdf5(expected_path):\n",
    "        print(f\"✅ Success! Valid HDF5 file available at: {expected_path}\")\n",
    "    else:\n",
    "        print(f\"❌ Error: File exists at {expected_path} but is NOT a valid HDF5 file.\")\n",
    "        print(\"This often means the download link is broken (404) or the file is corrupted.\")\n",
    "        file_size = os.path.getsize(expected_path)\n",
    "        print(f\"File Size: {file_size / 1024 / 1024:.2f} MB\")\n",
    "        if file_size < 10000: # If smaller than 10KB, it's likely text (error msg)\n",
    "            with open(expected_path, 'r', errors='ignore') as f:\n",
    "                print(\"Head of file content:\", f.read(200))\n",
    "else:\n",
    "    print(f\"❌ Error: Dataset file not found at {expected_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (Arguments)\n",
    "# Change these values to control the experiment\n",
    "\n",
    "class Args:\n",
    "    # Dataset settings\n",
    "    dataset = \"COCO-I2I\"  # Choices: 'DEEP1B', 'Last.fm', 'COCO-I2I', 'COCO-T2I', 'NYTimes', 'glove-25', 'glove-50', 'glove-100', 'glove-200'\n",
    "    num_subset = 50000    # Subset size if applicable\n",
    "\n",
    "    # Experiment Mode\n",
    "    find_best_recall = True  # Set to True to search for best alpha/beta. Set to False for single inference.\n",
    "    \n",
    "    # Similarity Method\n",
    "    similarity = \"segmented_cosine\"  # Choices: 'L1norm', 'cosine', 'segmented_cosine', 'LSH'\n",
    "    \n",
    "    # Hyperparameters for Seg-Cos / Experiment\n",
    "    dimension = 512       # Dimension of extracted feature\n",
    "    coupled_dimension = 2 # Dimension of segments (e.g., 2 for pairs)\n",
    "    N = 64                # Quantization levels (e.g., 64)\n",
    "    \n",
    "    # Option for the algorithm\n",
    "    # Choices: 'CSI', 'JI', 'TLE', 'HD', 'Seg-Cos_Real_Float', 'Seg-Cos_Float', \n",
    "    #          'Seg-Cos_QuantAng', 'Seg-Cos_QuantAngMag', 'Seg-Cos_Fixed', 'Seg-Cos_TCAM', 'Seg-Cos_TCAM_Bit'\n",
    "    option = \"Seg-Cos_TCAM\" \n",
    "\n",
    "    # Bound type\n",
    "    bound = \"upper\"       # Choices: 'upper', 'lower', 'complementary'\n",
    "    \n",
    "    # Alpha and Beta (Search Range or Fixed Values)\n",
    "    alpha = 1.0           # Scale factor / Start of alpha search\n",
    "    beta = 0.4            # Offset/Bias / Start of beta search\n",
    "    \n",
    "    # Normalization & Factors\n",
    "    normalization = True  # Whether to use normalization\n",
    "    complete = True       # Complete the normalization\n",
    "    factor = 0.359375     # Factor parameter\n",
    "    \n",
    "    # Batching\n",
    "    batch_size = 100      # Batch size for processing\n",
    "    query_num = 100       # Number of queries to process at a time\n",
    "    total_query_num = 0   # Total queries to process (0 = all)\n",
    "    topk = 1000           # Top-K recall calculation\n",
    "\n",
    "    # Other Params (defaults from script)\n",
    "    param = 0\n",
    "    minimum_clamp = False\n",
    "    angle = None         # Choices: 'ln', 'arccos'\n",
    "    clip_value = 0.3\n",
    "    tolerance_scale = 10\n",
    "    positive_similarity = False\n",
    "    positive_predict = False\n",
    "    tolerance_remap = False\n",
    "    tolerance_remap_target = \"mean\"\n",
    "    tolerance_function = \"linear\"\n",
    "    no_store_result = False\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm # Use notebook version of tqdm\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "# plt.switch_backend('Agg') # Usually not needed in notebooks where we want inline plots\n",
    "\n",
    "class SupportSetDataset():\n",
    "    def __init__(self, support_set):\n",
    "        self.support_set = torch.tensor(support_set, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.support_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.support_set[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_compute_cosine(support_loader, xq, topk=1000):\n",
    "    device = xq.device  \n",
    "    # gamma = -0.5\n",
    "    # xq_norm = torch.sqrt(torch.sum(xq**2, dim=1)) + 1e-12\n",
    "    # xq = torch.sign(xq) * torch.abs(xq) ** gamma\n",
    "    iq_norm = torch.sqrt(torch.sum(xq**2, dim=1)) + 1e-12\n",
    "    \n",
    "    all_similarities = []\n",
    "\n",
    "    for xb in tqdm(support_loader, desc=\"Cosine Calculation\"):\n",
    "        xb = xb.to(device)\n",
    "        # xb = torch.sign(xb) * torch.abs(xb) ** gamma\n",
    "        xb_norm = torch.sqrt(torch.sum(xb**2, dim=1)) + 1e-12\n",
    "\n",
    "        similarity = torch.matmul(xq, xb.T) / (iq_norm[:, None] * xb_norm[None, :])\n",
    "        similarity = torch.clamp(similarity, min=-1.0, max=1.0)\n",
    "        similarity = -1 * torch.acos(similarity) / math.pi * 180\n",
    "        # similarity = -1*torch.sqrt(torch.sum((xq[:,None,:] - xb[None,:,:])**2, dim=2))\n",
    "        all_similarities.append(similarity.detach().cpu())\n",
    "   \n",
    "    all_similarities = torch.cat(all_similarities, dim=1)\n",
    "\n",
    "    topk_values, topk_indices = torch.topk(all_similarities, k=topk, dim=1)\n",
    "    # plt.figure(figsize=(6,4))\n",
    "    # plt.hist(-1*all_similarities[0].flatten().cpu().numpy(), bins=100, color='steelblue', edgecolor='black')\n",
    "    # plt.title(f\"Angular Difference Distribution\")\n",
    "    # plt.xlabel(\"Value (Degree)\")\n",
    "    # plt.ylabel(\"Frequency\")\n",
    "    # plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(f\"similarity.png\")\n",
    "    # print(a)\n",
    "    all_similarities = all_similarities.flatten()\n",
    "\n",
    "    return topk_indices, torch.mean(all_similarities), torch.std(all_similarities)\n",
    "\n",
    "def do_compute_L1norm(support_loader, xq, topk=1000, clamp_ratio = 0.0):\n",
    "    device = xq.device  \n",
    "\n",
    "    all_similarities = []\n",
    "    xq_norm = torch.sqrt(torch.sum(xq**2, dim=1))\n",
    "    if(args.normalization):\n",
    "        xq = xq / xq_norm[:, None]\n",
    "\n",
    "    if(args.normalization):\n",
    "        support_data = support_loader.dataset.support_set\n",
    "        support_norm = torch.sqrt(torch.sum(support_data**2, dim=1))\n",
    "        normalized_support_set = support_data / support_norm[:, None]\n",
    "        max_value = torch.max(normalized_support_set).item()\n",
    "        min_value = torch.min(normalized_support_set).item()\n",
    "    else:\n",
    "        max_value = torch.max(support_loader.dataset.support_set).item()\n",
    "        min_value = torch.min(support_loader.dataset.support_set).item()\n",
    "    range_value = (max_value - min_value)\n",
    "\n",
    "    mean_value = (max_value + min_value) / 2\n",
    "    max_value = mean_value + (1 - clamp_ratio) * range_value / 2\n",
    "    min_value = mean_value - (1 - clamp_ratio) * range_value / 2\n",
    "    range_value = (1 - clamp_ratio) * range_value\n",
    "    # xq = torch.round(((xq - min_value) / range_value) * (args.N - 1))\n",
    "    xq = torch.clamp(torch.floor(((xq - min_value) / range_value) * args.N), 0, args.N-1)\n",
    "    # xq = torch.clamp(xq, min=min_value, max=max_value)\n",
    "\n",
    "    for xb in tqdm(support_loader, desc=\"L1Norm Calculation\"):\n",
    "        xb = xb.to(device)\n",
    "        if(args.normalization):\n",
    "            xb_norm = torch.sqrt(torch.sum(xb**2, dim=1))\n",
    "            xb = xb / xb_norm[:, None]\n",
    "        # xb = torch.round(((xb - min_value) / range_value) * (args.N - 1))\n",
    "        xb = torch.clamp(torch.floor(((xb - min_value) / range_value) * args.N), 0, args.N-1)\n",
    "        # xb = torch.clamp(xb, min=min_value, max=max_value)\n",
    "        # similarity = -1*torch.max(torch.abs(xq[:,None,:] - xb[None,:,:]), dim=2)[0]\n",
    "        similarity = -1*torch.mean(torch.abs(xq[:,None,:] - xb[None,:,:]), dim=2)\n",
    "        all_similarities.append(similarity.detach().cpu())\n",
    "   \n",
    "    all_similarities = torch.cat(all_similarities, dim=1)\n",
    "\n",
    "    topk_values, topk_indices = torch.topk(all_similarities, k=topk, dim=1)\n",
    "    all_similarities = all_similarities.flatten()\n",
    "\n",
    "    return topk_indices, torch.mean(all_similarities), torch.mean(all_similarities), torch.std(all_similarities)\n",
    "\n",
    "def do_compute_lsh(support_loader, xq, L, hashing_matrix, topk=1000):\n",
    "    device = xq.device  \n",
    "    xq_norm = torch.sqrt(torch.sum(xq**2, dim=1))\n",
    "\n",
    "    all_differences  = []\n",
    "    all_similarities = []\n",
    "\n",
    "    if(args.normalization):\n",
    "        xq = xq / xq_norm[:, None]\n",
    "\n",
    "    for xb in tqdm(support_loader, desc=\"LSH Calculation\"):\n",
    "        xb = xb.to(device)\n",
    "        xb_norm = torch.sqrt(torch.sum(xb**2, dim=1))\n",
    "\n",
    "        similarity_truth = torch.matmul(xq, xb.T) / (xq_norm[:, None] * xb_norm[None, :])\n",
    "        similarity_truth = torch.clamp(similarity_truth, -1, 1)\n",
    "        angle_truth      = -1 * torch.acos(similarity_truth) / math.pi * 180\n",
    "        if(args.normalization):\n",
    "            xb = xb / xb_norm[:, None]\n",
    "        hashed_query_vector = torch.matmul(xq, hashing_matrix)\n",
    "        hashed_key_memory   = torch.matmul(xb, hashing_matrix)\n",
    "        ###\n",
    "        hashed_query_vector = (hashed_query_vector > 0).float()\n",
    "        hashed_key_memory   = (hashed_key_memory   > 0).float()\n",
    "        similarity          = torch.cos(torch.mean(torch.abs(hashed_query_vector[:, None, :] - hashed_key_memory[None, :, :]), dim=2) * math.pi)\n",
    "        similarity          = torch.clamp(similarity, -1, 1)\n",
    "        similarity          = -1 * torch.acos(similarity) / math.pi * 180\n",
    "        \n",
    "        \n",
    "        # similarity = -1*torch.sqrt(torch.sum((hashed_query_vector[:,None,:] - hashed_key_memory[None,:,:])**2, dim=2))\n",
    "        all_differences.append((angle_truth - similarity).detach().cpu())\n",
    "        all_similarities.append(similarity.detach().cpu())\n",
    "   \n",
    "    all_differences = torch.cat(all_differences, dim=1)\n",
    "    all_similarities = torch.cat(all_similarities, dim=1)\n",
    "\n",
    "    topk_values, topk_indices = torch.topk(all_similarities, k=topk, dim=1)\n",
    "    all_differences = all_differences.flatten()\n",
    "    all_similarities = all_similarities.flatten()\n",
    "\n",
    "    return topk_indices, torch.mean(all_similarities).item(), torch.mean(all_differences).item(), torch.std(all_differences).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82344d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global correlation_array\n",
    "global gap_array\n",
    "correlation_array = []\n",
    "gap_array         = []\n",
    "\n",
    "def do_compute_segmented_cosine(support_loader, query_vector, topk=1000, scale=None, minimum=None):\n",
    "    device           = query_vector.device \n",
    "    query_vector     = query_vector[:, :args.dimension] \n",
    "    query_vector_mag = torch.sqrt(torch.sum(query_vector**2, dim=1)) + 1e-12\n",
    "\n",
    "    query_vector_circular = torch.cat((query_vector, query_vector[:,:args.coupled_dimension-1]), dim=1)\n",
    "    idx                   = torch.arange(args.coupled_dimension).unsqueeze(0) + torch.arange(args.dimension).unsqueeze(1)\n",
    "    query_segment         = query_vector_circular[:,idx]\n",
    "    query_segment_mag     = torch.sqrt(torch.sum(query_segment**2, dim=2)) + 1e-12\n",
    "    \n",
    "    if(args.option == \"Seg-Cos_TCAM_Bit\"):\n",
    "        plane_index = torch.arange(args.N//2).to(device)\n",
    "        plane_angle = -math.pi / args.N - plane_index * (2*math.pi / args.N)\n",
    "        normal_matrix = torch.stack((torch.sin(plane_angle), -torch.cos(plane_angle)), dim=1)\n",
    "        query_segment_mag_ = torch.abs(torch.matmul(query_segment, normal_matrix.T))\n",
    "    \n",
    "    all_differences  = []\n",
    "    all_similarities = []\n",
    "    all_angles       = []\n",
    "    all_weight_mean      = []\n",
    "    all_similarity_truth = []\n",
    "\n",
    "    # data_array = []\n",
    "\n",
    "    for support_vector in tqdm(support_loader, desc=\"Segmented Cosine\"):\n",
    "        support_vector     = support_vector.to(device)\n",
    "        support_vector     = support_vector[:, :args.dimension]\n",
    "        support_vector_mag = torch.sqrt(torch.sum(support_vector**2, dim=1)) + 1e-12\n",
    "\n",
    "        similarity_truth = torch.matmul(query_vector, support_vector.T) / (query_vector_mag[:, None] * support_vector_mag[None, :])\n",
    "        similarity_truth = torch.clamp(similarity_truth, -1, 1)\n",
    "        angle_truth      = -1 * torch.acos(similarity_truth) / math.pi * 180\n",
    "\n",
    "        support_vector_circular = torch.cat((support_vector, support_vector[:,:args.coupled_dimension-1]), dim=1)\n",
    "        support_segment         = support_vector_circular[:,idx]\n",
    "        support_segment_mag     = torch.sqrt(torch.sum(support_segment**2, dim=2)) + 1e-12\n",
    "\n",
    "        if(args.option == \"Seg-Cos_TCAM_Bit\"):\n",
    "            plane_index = torch.arange(args.N//2).to(device)\n",
    "            plane_angle = -math.pi / args.N - plane_index * (2*math.pi / args.N)\n",
    "            normal_matrix = torch.stack((torch.sin(plane_angle), -torch.cos(plane_angle)), dim=1)\n",
    "            support_segment_mag_ = torch.abs(torch.matmul(support_segment, normal_matrix.T))\n",
    "        \n",
    "        weight_support = math.sqrt(args.dimension / args.coupled_dimension) * (support_segment_mag / support_vector_mag[:,None])\n",
    "        weight_query   = math.sqrt(args.dimension / args.coupled_dimension) * (  query_segment_mag /   query_vector_mag[:,None])\n",
    "        \n",
    "        segmented_similarity = torch.sum(query_segment[:, None, :, :] * support_segment[None, :, :, :], dim=3) / (query_segment_mag[:, None, :] * support_segment_mag[None, :, :])\n",
    "        segmented_similarity = torch.clamp(segmented_similarity, -1+1e-7, 1-1e-7)\n",
    "        weight               = weight_support[None, :, :] * weight_query[:, None, :]\n",
    "        \n",
    "        # Cauchy–Schwarz Inequality \n",
    "        if(args.option == \"CSI\"):\n",
    "            segment_lower_estimate = weight * (1 - segmented_similarity)\n",
    "            segment_upper_estimate = weight * (1 + segmented_similarity)\n",
    "        # Jensen's Inequality \n",
    "        elif(args.option == \"JI\"):\n",
    "            segment_lower_estimate = torch.log(weight) + torch.log(1 - segmented_similarity)\n",
    "            segment_upper_estimate = torch.log(weight) + torch.log(1 + segmented_similarity)\n",
    "        # Taylor Expansion  \n",
    "        elif(args.option == \"TLE\"):\n",
    "            t_lower    = 2*math.atan(1/(scale))\n",
    "            bias_lower = ((0-t_lower)*scale) + math.log(1-math.cos(t_lower))\n",
    "            segment_lower_estimate = torch.log(weight) + (scale*torch.acos(segmented_similarity) + bias_lower)\n",
    "            t_upper    = 2*math.atan(scale)\n",
    "            bias_upper = ((t_upper-math.pi)*scale) + math.log(1+math.cos(t_upper))\n",
    "            segment_upper_estimate = torch.log(weight) + (scale*(math.pi-torch.acos(segmented_similarity)) + bias_upper)\n",
    "        # Hamming Distance \n",
    "        elif(args.option == \"HD\"):\n",
    "            if(args.angle == \"ln\"):\n",
    "                segment_lower_estimate = torch.log(1 - segmented_similarity)\n",
    "                segment_upper_estimate = torch.log(1 + segmented_similarity)\n",
    "            elif(args.angle == \"arccos\"):\n",
    "                segment_lower_estimate = torch.acos(segmented_similarity) - math.pi/2\n",
    "                segment_upper_estimate = math.pi/2 - torch.acos(segmented_similarity) \n",
    "            else:\n",
    "                segment_lower_estimate = -1 * segmented_similarity\n",
    "                segment_upper_estimate = segmented_similarity\n",
    "\n",
    "        elif(args.option == \"Seg-Cos_Real_Float\"):\n",
    "            quantized_weight_support = torch.clamp(torch.log(weight_support) - (minimum / 2), max=0)\n",
    "            quantized_weight_query   = torch.clamp(torch.log(weight_query)   - (minimum / 2), max=0)\n",
    "            \n",
    "            if(args.normalization):\n",
    "                mean_weight_support = torch.mean(quantized_weight_support, dim=1)\n",
    "                quantized_weight_support = -1*math.pi*args.factor * quantized_weight_support / mean_weight_support[:, None]\n",
    "                quantized_weight_support = torch.where(mean_weight_support[:, None] == 0, -1*math.pi*args.factor, quantized_weight_support)\n",
    "                if(args.complete):\n",
    "                    mean_weight_query = torch.mean(quantized_weight_query, dim=1)\n",
    "                    quantized_weight_query = -1*math.pi*args.factor * quantized_weight_query / mean_weight_query[:, None]\n",
    "                    quantized_weight_query = torch.where(mean_weight_query[:, None] == 0, -1*math.pi*args.factor, quantized_weight_query)\n",
    "            segment_lower_estimate = quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + torch.log(1-segmented_similarity) - (1 / scale)\n",
    "            segment_upper_estimate = quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + torch.log(1+segmented_similarity) - (1 / scale)\n",
    "        \n",
    "        elif(args.option == \"Seg-Cos_Float\"):\n",
    "            t    = 2*math.atan(1/(scale))\n",
    "            bias = ((0-t)*scale) + math.log(1-math.cos(t))\n",
    "            quantized_weight_support = (1/scale) * (torch.log(weight_support) + ((bias - minimum) / 2))\n",
    "            quantized_weight_query   = (1/scale) * (torch.log(weight_query)   + ((bias - minimum) / 2))\n",
    "\n",
    "            quantized_weight_support = torch.clamp(quantized_weight_support, max=0)\n",
    "            quantized_weight_query   = torch.clamp(quantized_weight_query,   max=0)\n",
    "            \n",
    "            if(args.normalization):\n",
    "                mean_weight_support = torch.mean(quantized_weight_support, dim=1)\n",
    "                quantized_weight_support = quantized_weight_support + (-1*math.pi*args.factor - mean_weight_support[:, None]) * quantized_weight_support / mean_weight_support[:, None]\n",
    "                if(args.complete):\n",
    "                    mean_weight_query = torch.mean(quantized_weight_query, dim=1)\n",
    "                    quantized_weight_query = quantized_weight_query + (-1*math.pi*args.factor - mean_weight_query[:, None]) * quantized_weight_query / mean_weight_query[:, None]\n",
    "\n",
    "            maximum_distance = torch.clamp(math.pi + 2*torch.minimum(quantized_weight_support[None, :, :], quantized_weight_query[:, None, :]), min=0)\n",
    "            segment_lower_estimate = torch.clamp(quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + torch.acos(segmented_similarity),         max=maximum_distance)\n",
    "            segment_upper_estimate = torch.clamp(quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + math.pi-torch.acos(segmented_similarity), max=maximum_distance)\n",
    "\n",
    "        elif(args.option == \"Seg-Cos_QuantAng\"):\n",
    "            division = 2*math.pi/args.N\n",
    "            angle_query_segment   = torch.atan2(  query_segment[:,:,1],   query_segment[:,:,0])\n",
    "            angle_support_segment = torch.atan2(support_segment[:,:,1], support_segment[:,:,0])\n",
    "            angle_query_segment   = torch.round(  angle_query_segment / division)\n",
    "            angle_support_segment = torch.round(angle_support_segment / division)\n",
    "            angle_query_segment   = torch.where(  angle_query_segment < 0, args.N +   angle_query_segment,   angle_query_segment)\n",
    "            angle_support_segment = torch.where(angle_support_segment < 0, args.N + angle_support_segment, angle_support_segment)\n",
    "            angle_difference = torch.abs(angle_query_segment[:, None, :] - angle_support_segment[None, :, :])\n",
    "            angle_difference = torch.min(angle_difference, args.N - angle_difference) * division\n",
    "\n",
    "            t_lower    = 2*math.atan(1/scale)\n",
    "            bias_lower = ((0-t_lower)*scale) + math.log(1-math.cos(t_lower))\n",
    "            segment_lower_estimate = (1/scale) * (torch.log(weight) + (scale*angle_difference + bias_lower) - minimum)\n",
    "            t_upper    = 2*math.atan(scale)\n",
    "            bias_upper = ((t_upper-math.pi)*scale) + math.log(1+math.cos(t_upper))\n",
    "            segment_upper_estimate = (1/scale) * (torch.log(weight) + (scale*(math.pi-angle_difference) + bias_upper) - minimum)\n",
    "        \n",
    "        elif(args.option == \"Seg-Cos_QuantAngMag\"):\n",
    "            division = 2*math.pi/args.N\n",
    "            angle_query_segment   = torch.atan2(  query_segment[:,:,1],   query_segment[:,:,0])\n",
    "            angle_support_segment = torch.atan2(support_segment[:,:,1], support_segment[:,:,0])\n",
    "            angle_query_segment   = torch.round(  angle_query_segment / division)\n",
    "            angle_support_segment = torch.round(angle_support_segment / division)\n",
    "            angle_query_segment   = torch.where(  angle_query_segment < 0, args.N +   angle_query_segment,   angle_query_segment)\n",
    "            angle_support_segment = torch.where(angle_support_segment < 0, args.N + angle_support_segment, angle_support_segment)\n",
    "            angle_difference = torch.abs(angle_query_segment[:, None, :] - angle_support_segment[None, :, :])\n",
    "            angle_difference = torch.min(angle_difference, args.N - angle_difference)\n",
    "\n",
    "            t_lower    = 2*math.atan(1/scale)\n",
    "            bias_lower = ((0-t_lower)*scale) + math.log(1-math.cos(t_lower))\n",
    "            quantized_lower_weight_support = torch.round((1/scale) * (torch.log(weight_support) + ((bias_lower - minimum) / 2)) / division)\n",
    "            quantized_lower_weight_query   = torch.round((1/scale) * (torch.log(weight_query)   + ((bias_lower - minimum) / 2)) / division)\n",
    "            segment_lower_estimate = quantized_lower_weight_support[None, :, :] + quantized_lower_weight_query[:, None, :] + angle_difference\n",
    "            segment_lower_estimate = segment_lower_estimate * division\n",
    "\n",
    "            t_upper    = 2*math.atan(scale)\n",
    "            bias_upper = ((t_upper-math.pi)*scale) + math.log(1+math.cos(t_upper))\n",
    "            quantized_upper_weight_support = torch.round((1/scale) * (torch.log(weight_support) + ((bias_upper - minimum) / 2)) / division)\n",
    "            quantized_upper_weight_query   = torch.round((1/scale) * (torch.log(weight_query)   + ((bias_upper - minimum) / 2)) / division)\n",
    "            segment_upper_estimate = quantized_upper_weight_support[None, :, :] + quantized_upper_weight_query[:, None, :] + ((args.N/2)-angle_difference)\n",
    "            segment_upper_estimate = segment_upper_estimate * division\n",
    "\n",
    "        elif(args.option == \"Seg-Cos_Fixed\"):\n",
    "            division = 2*math.pi/args.N\n",
    "            angle_query_segment   = torch.atan2(  query_segment[:,:,1],   query_segment[:,:,0])\n",
    "            angle_support_segment = torch.atan2(support_segment[:,:,1], support_segment[:,:,0])\n",
    "            angle_query_segment   = torch.round(  angle_query_segment / division)\n",
    "            angle_support_segment = torch.round(angle_support_segment / division)\n",
    "            angle_query_segment   = torch.where(  angle_query_segment < 0, args.N +   angle_query_segment,   angle_query_segment)\n",
    "            angle_support_segment = torch.where(angle_support_segment < 0, args.N + angle_support_segment, angle_support_segment)\n",
    "            angle_difference = torch.abs(angle_query_segment[:, None, :] - angle_support_segment[None, :, :])\n",
    "            angle_difference = torch.min(angle_difference, args.N - angle_difference)\n",
    "\n",
    "            t    = 2*math.atan(1/scale)\n",
    "            bias = ((0-t)*scale) + math.log(1-math.cos(t))\n",
    "            quantized_weight_support = torch.round((1/scale) * (torch.log(weight_support) + ((bias - minimum) / 2)) / division)\n",
    "            quantized_weight_query   = torch.round((1/scale) * (torch.log(weight_query)   + ((bias - minimum) / 2)) / division)\n",
    "            quantized_weight_support = torch.clamp(quantized_weight_support, max=0)\n",
    "            quantized_weight_query   = torch.clamp(quantized_weight_query,   max=0)\n",
    "            segment_lower_estimate = quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + angle_difference\n",
    "            segment_upper_estimate = quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + ((args.N/2)-angle_difference)\n",
    "            segment_lower_estimate = segment_lower_estimate * division\n",
    "            segment_upper_estimate = segment_upper_estimate * division\n",
    "\n",
    "        elif(args.option == \"Seg-Cos_TCAM\"):\n",
    "            # print(query_segment[0,1:3])\n",
    "            # print(query_segment[53,1:3])\n",
    "            # print(query_segment[23,1:3])\n",
    "            division = 2*math.pi/args.N\n",
    "            angle_query_segment   = torch.atan2(  query_segment[:,:,1],   query_segment[:,:,0])\n",
    "            angle_support_segment = torch.atan2(support_segment[:,:,1], support_segment[:,:,0])\n",
    "            angle_query_segment   = torch.round(  angle_query_segment / division)\n",
    "            angle_support_segment = torch.round(angle_support_segment / division)\n",
    "            angle_query_segment   = torch.where(  angle_query_segment < 0, args.N +   angle_query_segment,   angle_query_segment)\n",
    "            angle_support_segment = torch.where(angle_support_segment < 0, args.N + angle_support_segment, angle_support_segment)\n",
    "            angle_difference = torch.abs(angle_query_segment[:, None, :] - angle_support_segment[None, :, :])\n",
    "            angle_difference = torch.min(angle_difference, args.N - angle_difference)\n",
    "\n",
    "            t    = 2*math.atan(1/scale)\n",
    "            bias = ((0-t)*scale) + math.log(1-math.cos(t))\n",
    "            quantized_weight_support = (1/scale) * (torch.log(weight_support) + ((bias - minimum) / 2))\n",
    "            quantized_weight_query   = (1/scale) * (torch.log(weight_query)   + ((bias - minimum) / 2))\n",
    "            quantized_weight_support = torch.clamp(quantized_weight_support, max=0)\n",
    "            quantized_weight_query   = torch.clamp(quantized_weight_query,   max=0)\n",
    "            if(args.normalization):\n",
    "                num_to_set = round(args.dimension * args.factor)\n",
    "                if((args.N == 2) or (args.N == 4)):\n",
    "                    _, indices = torch.topk(-quantized_weight_support, num_to_set, dim=1)\n",
    "                    quantized_weight_support = torch.zeros_like(quantized_weight_support)\n",
    "                    quantized_weight_support.scatter_(1, indices, -math.pi)\n",
    "                else:\n",
    "                    mean_weight_support = torch.mean(quantized_weight_support, dim=1)\n",
    "                    # quantized_weight_support = quantized_weight_support + (-1*math.pi*args.factor - mean_weight_support[:, None]) * quantized_weight_support / mean_weight_support[:, None]\n",
    "                    quantized_weight_support = -1*math.pi*args.factor * quantized_weight_support / mean_weight_support[:, None]\n",
    "                    quantized_weight_support = torch.where(mean_weight_support[:, None] == 0, -1*math.pi*args.factor, quantized_weight_support)\n",
    "                if(args.complete):\n",
    "                    if((args.N == 2) or (args.N == 4)):\n",
    "                        _, indices = torch.topk(-quantized_weight_query, num_to_set, dim=1)\n",
    "                        quantized_weight_query = torch.zeros_like(quantized_weight_query)\n",
    "                        quantized_weight_query.scatter_(1, indices, -math.pi)\n",
    "                    else:\n",
    "                        mean_weight_query = torch.mean(quantized_weight_query, dim=1)\n",
    "                        # quantized_weight_query = quantized_weight_query + (-1*math.pi*args.factor - mean_weight_query[:, None]) * quantized_weight_query / mean_weight_query[:, None]\n",
    "                        quantized_weight_query = -1*math.pi*args.factor * quantized_weight_query / mean_weight_query[:, None]\n",
    "                        quantized_weight_query = torch.where(mean_weight_query[:, None] == 0, -1*math.pi*args.factor, quantized_weight_query)\n",
    "\n",
    "            quantized_weight_support_round = torch.round(quantized_weight_support / division)\n",
    "            quantized_weight_query_round   = torch.round(quantized_weight_query   / division)\n",
    "\n",
    "            quantized_weight_support = quantized_weight_support_round\n",
    "            quantized_weight_query   = quantized_weight_query_round\n",
    "                \n",
    "            maximum_distance = torch.clamp((args.N/2) + 2*torch.minimum(quantized_weight_support[None, :, :], quantized_weight_query[:, None, :]), min=0)\n",
    "\n",
    "            segment_lower_estimate = torch.clamp(quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + angle_difference,            max=maximum_distance)\n",
    "            segment_lower_estimate = segment_lower_estimate * division\n",
    "            segment_upper_estimate = torch.clamp(quantized_weight_support[None, :, :] + quantized_weight_query[:, None, :] + (args.N/2)-angle_difference, max=maximum_distance)\n",
    "            # segment_upper_estimate = torch.clamp((args.N/2)-angle_difference, max=maximum_distance)\n",
    "            segment_upper_estimate = segment_upper_estimate * division\n",
    "\n",
    "        elif(args.option == \"Seg-Cos_TCAM_Bit\"):\n",
    "            division = 2*math.pi/args.N\n",
    "            angle_query_segment   = torch.atan2(  query_segment[:,:,1],   query_segment[:,:,0])\n",
    "            angle_support_segment = torch.atan2(support_segment[:,:,1], support_segment[:,:,0])\n",
    "            angle_query_segment   = torch.round(  angle_query_segment / division)\n",
    "            angle_support_segment = torch.round(angle_support_segment / division)\n",
    "            angle_query_segment   = torch.where(  angle_query_segment < 0, args.N +   angle_query_segment,   angle_query_segment)\n",
    "            angle_support_segment = torch.where(angle_support_segment < 0, args.N + angle_support_segment, angle_support_segment)\n",
    "            codeword = torch.arange(args.N//2).to(device)\n",
    "            codeword = codeword.unsqueeze(0) + torch.arange(args.N).to(device).unsqueeze(1)\n",
    "            codeword = codeword % (args.N)\n",
    "            codeword = codeword >= (args.N // 2)\n",
    "            \n",
    "            codeword_query   = codeword[angle_query_segment.long()]\n",
    "            codeword_support = codeword[angle_support_segment.long()]\n",
    "\n",
    "            angle_difference = codeword_query[:, None, :, :] ^ codeword_support[None, :, :, :]\n",
    "            \n",
    "            # Fixed potential unbound variable error if Seg-Cos_TCAM_Bit is used straight away, \n",
    "            # but likely args.option logic separation handles it.\n",
    "            # Using the same logic as Seg-Cos_TCAM for quantized_weight_*\n",
    "\n",
    "            t    = 2*math.atan(1/scale)\n",
    "            bias = ((0-t)*scale) + math.log(1-math.cos(t))\n",
    "            # Note: The original code for Seg-Cos_TCAM_Bit seemed to use variables from other scopes or needed more setup.\n",
    "            # Assuming the weights are calculated similarly to Seg-Cos_TCAM or other blocks if not explicitly defined.\n",
    "            # Checking original code, quantized_weight_support seems to come from arguments or previous calcs.\n",
    "            # BUT, in the original code, Seg-Cos_TCAM_Bit uses `quantized_weight_support` which was defined in Seg-Cos_TCAM block?? \n",
    "            # No, it's a separate elif. \n",
    "            # Ah, in the original code, `Seg-Cos_TCAM_Bit` logic uses `quantized_weight_support` but doesn't calculate it in its own block?\n",
    "            # Let's re-read the original file lines 580+. \n",
    "            # It seems it re-calculates or uses logic similar to others. \n",
    "            # Wait, line 588 in original code: `if(args.normalization): ... ` \n",
    "            # But where is `quantized_weight_support` defined?\n",
    "            # It seems the `Seg-Cos_TCAM_Bit` block in original code might rely on state or I missed a part.\n",
    "            # Let's implement what I see, but add safety.\n",
    "            \n",
    "            # Recalculating weights for Bit version if not present\n",
    "            quantized_weight_support = (1/scale) * (torch.log(weight_support) + ((bias - minimum) / 2))\n",
    "            quantized_weight_query   = (1/scale) * (torch.log(weight_query)   + ((bias - minimum) / 2))\n",
    "            quantized_weight_support = torch.clamp(quantized_weight_support, max=0)\n",
    "            quantized_weight_query   = torch.clamp(quantized_weight_query,   max=0)\n",
    "\n",
    "            if(args.normalization):\n",
    "                num_to_set = math.floor(args.dimension * args.factor * (args.N // 2))\n",
    "                support_segment_mag_ = support_segment_mag_.view(support_segment_mag_.shape[0], -1)\n",
    "                _, indices = torch.topk(-support_segment_mag_, num_to_set, dim=1)\n",
    "                quantized_weight_support = torch.ones_like(support_segment_mag_)\n",
    "                quantized_weight_support.scatter_(1, indices, 0)\n",
    "                quantized_weight_support = quantized_weight_support.view(support_segment_mag_.shape[0], -1, args.N // 2)\n",
    "                if(args.complete):\n",
    "                    query_segment_mag_ = query_segment_mag_.view(query_segment_mag_.shape[0], -1)\n",
    "                    _, indices = torch.topk(-query_segment_mag_, num_to_set, dim=1)\n",
    "                    quantized_weight_query = torch.ones_like(query_segment_mag_)\n",
    "                    quantized_weight_query.scatter_(1, indices, 0)\n",
    "                    quantized_weight_query = quantized_weight_query.view(quantized_weight_query.shape[0], -1, args.N // 2)\n",
    "\n",
    "            segment_lower_estimate = torch.sum(angle_difference    * quantized_weight_support[None, :, :, :] * quantized_weight_query[:, None, :, :], dim=3)\n",
    "            segment_upper_estimate = torch.sum((~angle_difference) * quantized_weight_support[None, :, :, :] * quantized_weight_query[:, None, :, :], dim=3)\n",
    "\n",
    "            segment_lower_estimate = segment_lower_estimate * division\n",
    "            segment_upper_estimate = segment_upper_estimate * division\n",
    "\n",
    "        if(\"Seg-Cos\" in args.option):\n",
    "            segment_lower_estimate = torch.clamp(segment_lower_estimate, min=0) # * scale + minimum\n",
    "            segment_upper_estimate = torch.clamp(segment_upper_estimate, min=0) # * scale + minimum\n",
    "        else:\n",
    "            if(args.minimum_clamp):\n",
    "                segment_lower_estimate = torch.clamp(segment_lower_estimate, min=minimum)\n",
    "                segment_upper_estimate = torch.clamp(segment_upper_estimate, min=minimum)\n",
    "        \n",
    "        lower_estimate = -1*torch.mean(segment_lower_estimate, dim=2)\n",
    "        upper_estimate =    torch.mean(segment_upper_estimate, dim=2)\n",
    "        weight_mean = torch.mean(weight, dim=2)\n",
    "        \n",
    "        all_weight_mean.append(weight_mean)\n",
    "        all_similarity_truth.append(similarity_truth)\n",
    "        \n",
    "        similarity = None\n",
    "        if(args.bound == \"lower\"):\n",
    "            similarity = lower_estimate\n",
    "        elif(args.bound == \"upper\"):\n",
    "            similarity = upper_estimate\n",
    "        elif(args.bound == \"complementary\"):\n",
    "            similarity = (lower_estimate + upper_estimate) / 2\n",
    "        \n",
    "        cosine = None\n",
    "        # Cauchy–Schwarz Inequality \n",
    "        if(args.option == \"CSI\"):\n",
    "            if(args.bound == \"lower\"):\n",
    "                cosine = similarity + 1\n",
    "            elif(args.bound == \"upper\"):\n",
    "                cosine = similarity - 1\n",
    "            elif(args.bound == \"complementary\"):\n",
    "                cosine = similarity\n",
    "        # Jensen's Inequality / Taylor / Seg-Cos\n",
    "        elif((args.option == \"JI\") or (args.option == \"TLE\") or ((args.option == \"HD\") and (args.angle == \"ln\")) or (\"Seg-Cos\" in args.option)):\n",
    "            if(args.bound == \"lower\"):\n",
    "                cosine = -1*torch.exp(-1*similarity) + 1\n",
    "            elif(args.bound == \"upper\"):\n",
    "                cosine = torch.exp(similarity) - 1\n",
    "            elif(args.bound == \"complementary\"):\n",
    "                cosine = 2 / (torch.exp(-1*similarity) + 1) - 1\n",
    "        # Hamming Distance \n",
    "        elif(args.option == \"HD\"):\n",
    "            if(args.angle == \"arccos\"):\n",
    "                cosine = torch.cos(similarity + math.pi/2)\n",
    "            else:\n",
    "                cosine = similarity\n",
    "        \n",
    "        angle = -1 * torch.acos(torch.clamp(cosine, -1, 1)) / math.pi * 180\n",
    "        \n",
    "        all_differences.append((angle_truth - angle).detach().cpu())\n",
    "        all_similarities.append(similarity.detach().cpu())\n",
    "        all_angles.append(angle.detach().cpu())\n",
    "\n",
    "    all_differences  = torch.cat(all_differences, dim=1)\n",
    "    all_similarities = torch.cat(all_similarities, dim=1)\n",
    "    all_angles       = torch.cat(all_angles, dim=1)\n",
    "    all_weight_mean      = torch.cat(all_weight_mean, dim=1)\n",
    "    all_similarity_truth = torch.cat(all_similarity_truth, dim=1)\n",
    "\n",
    "    topk_values, topk_indices = torch.topk(all_similarities, k=topk, dim=1)\n",
    "\n",
    "    all_differences = all_differences.flatten()\n",
    "    all_similarities = all_similarities.flatten()\n",
    "    all_angles = all_angles.flatten()\n",
    "\n",
    "    return topk_indices, torch.mean(all_angles).item(), torch.mean(all_differences).item(), torch.std(all_differences).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "    if args.dataset == \"glove-25\":\n",
    "        file_path = './GloVe/glove-25-angular.hdf5'\n",
    "    elif args.dataset == \"glove-50\":\n",
    "        file_path = './GloVe/glove-50-angular.hdf5'\n",
    "    elif args.dataset == \"glove-100\":\n",
    "        file_path = './GloVe/glove-100-angular.hdf5'\n",
    "    elif args.dataset == \"glove-200\":\n",
    "        file_path = './GloVe/glove-200-angular.hdf5'\n",
    "    elif args.dataset == \"NYTimes\":\n",
    "        file_path = './NYTimes/nytimes-256-angular.hdf5'\n",
    "    elif args.dataset == \"DEEP1B\":\n",
    "        file_path = './DEEP1B/deep-image-96-angular.hdf5'\n",
    "    elif args.dataset == \"Last.fm\":\n",
    "        file_path = './Last.fm/lastfm-64-dot.hdf5'\n",
    "    elif args.dataset == \"COCO-I2I\":\n",
    "        file_path = './COCO-I2I/coco-i2i-512-angular.hdf5'\n",
    "    elif args.dataset == \"COCO-T2I\":\n",
    "        file_path = './COCO-T2I/coco-t2i-512-angular.hdf5'\n",
    "    else:\n",
    "        file_path = f\"./{args.dataset}/{args.dataset}_{args.num_subset}.hdf5\"\n",
    "\n",
    "    total_query_num = args.total_query_num\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        print(\"Query Set shape:\", f['test'].shape)\n",
    "        if total_query_num == 0:\n",
    "            total_query_num = f['test'].shape[0]\n",
    "        support_set_dataset = SupportSetDataset(f['train'][:])\n",
    "        batch_size = args.batch_size\n",
    "        support_loader = DataLoader(support_set_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        print(\"Query Label shape:\", f['neighbors'].shape)\n",
    "        print(\"Support Set shape:\", f['train'].shape)\n",
    "\n",
    "        if(total_query_num % args.query_num != 0):\n",
    "            print(\"Error: The total query number is not divisible by the query number.\")\n",
    "\n",
    "    counter = 0\n",
    "    recall = 0\n",
    "    \n",
    "    if args.similarity == \"LSH\":\n",
    "        L = args.param\n",
    "        hashing_matrix = torch.randn((args.dimension, args.dimension*L), device=device)\n",
    "\n",
    "    while counter < total_query_num:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            test_set = torch.tensor(f['test'][counter : counter+args.query_num], dtype=torch.float32).to(device)\n",
    "            test_neighbors_id = f['neighbors'][counter : counter+args.query_num]\n",
    "\n",
    "        print(\"Processed query from\", counter, \"to\", counter + test_set.shape[0] - 1)\n",
    "\n",
    "        if args.similarity == \"cosine\":\n",
    "            result_id, average_similarity, std_similarity = do_compute_cosine(support_loader, test_set, topk=args.topk)\n",
    "            average_difference = average_similarity\n",
    "            std_difference = std_similarity\n",
    "        elif args.similarity == \"segmented_cosine\":\n",
    "            result_id, average_similarity, average_difference, std_difference = do_compute_segmented_cosine(support_loader, test_set, topk=args.topk, scale=(1 / args.alpha), minimum=args.beta)\n",
    "        elif args.similarity == \"LSH\":\n",
    "            result_id, average_similarity, average_difference, std_difference = do_compute_lsh(support_loader, test_set, L, hashing_matrix, topk=args.topk)\n",
    "        elif args.similarity == \"L1norm\":\n",
    "            result_id, average_similarity, average_difference, std_difference = do_compute_L1norm(support_loader, test_set, topk=args.topk)\n",
    "        average_similarity_array = []\n",
    "        average_difference_array = []\n",
    "        std_difference_array     = []\n",
    "\n",
    "        average_similarity_array.append(average_similarity)\n",
    "        average_difference_array.append(average_difference)\n",
    "        std_difference_array.append(std_difference)\n",
    "\n",
    "        for i in range(test_set.shape[0]):\n",
    "            # print(\"Query ID:\", i, \"Query Label:\", test_neighbors_id[i])\n",
    "            # print(\"Result ID:\", result_id[i])\n",
    "            intersection = torch.isin(result_id[i], torch.tensor(test_neighbors_id[i], device=result_id.device))\n",
    "            # print(\"Intersection:\", intersection.sum())\n",
    "            recall += intersection.sum().item() / len(test_neighbors_id[i])\n",
    "\n",
    "        counter += args.query_num\n",
    "\n",
    "    average_similarity = torch.tensor(average_similarity_array, device=device)\n",
    "    total_average_similarity = torch.mean(average_similarity)\n",
    "    average_difference = torch.tensor(average_difference_array, device=device)\n",
    "    total_average_difference = torch.mean(average_difference)\n",
    "    std_difference = torch.tensor(std_difference_array, device=device)\n",
    "    total_std_difference =  torch.sqrt(torch.mean((std_difference**2) + (average_difference - total_average_difference)**2))\n",
    "    print(\"Difference:\", total_average_difference, total_std_difference)\n",
    "    print(\"Similarity:\", total_average_similarity)\n",
    "\n",
    "    ave_recall = recall / total_query_num\n",
    "    print(\"Recall:\", ave_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_recall():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "    if args.dataset == \"glove-25\":\n",
    "        file_path = './GloVe/glove-25-angular.hdf5'\n",
    "    elif args.dataset == \"glove-50\":\n",
    "        file_path = './GloVe/glove-50-angular.hdf5'\n",
    "    elif args.dataset == \"glove-100\":\n",
    "        file_path = './GloVe/glove-100-angular.hdf5'\n",
    "    elif args.dataset == \"glove-200\":\n",
    "        file_path = './GloVe/glove-200-angular.hdf5'\n",
    "    elif args.dataset == \"NYTimes\":\n",
    "        file_path = './NYTimes/nytimes-256-angular.hdf5'\n",
    "    elif args.dataset == \"DEEP1B\":\n",
    "        file_path = './DEEP1B/deep-image-96-angular.hdf5'\n",
    "    elif args.dataset == \"Last.fm\":\n",
    "        file_path = './Last.fm/lastfm-64-dot.hdf5'\n",
    "    elif args.dataset == \"COCO-I2I\":\n",
    "        file_path = './COCO-I2I/coco-i2i-512-angular.hdf5'\n",
    "    elif args.dataset == \"COCO-T2I\":\n",
    "        file_path = './COCO-T2I/coco-t2i-512-angular.hdf5'\n",
    "    else:\n",
    "        file_path = f\"./{args.dataset}/{args.dataset}_{args.num_subset}.hdf5\"\n",
    "\n",
    "    total_query_num = args.total_query_num\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        print(\"Query Set shape:\", f['test'].shape)\n",
    "        if total_query_num == 0:\n",
    "            total_query_num = f['test'].shape[0]\n",
    "        support_set_dataset = SupportSetDataset(f['train'][:])\n",
    "        batch_size = args.batch_size\n",
    "        support_loader = DataLoader(support_set_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        print(\"Query Label shape:\", f['neighbors'].shape)\n",
    "        print(\"Support Set shape:\", f['train'].shape)\n",
    "\n",
    "        if(total_query_num % args.query_num != 0):\n",
    "            print(\"Error: The total query number is not divisible by the query number.\")\n",
    "\n",
    "    best_alpha  = None\n",
    "    best_beta   = None\n",
    "    best_recall = 0\n",
    "\n",
    "    # Hyperparameter Grid Search Range\n",
    "    alpha_start = args.alpha \n",
    "    alpha_end   = 2.1\n",
    "    alpha_step  = 0.1\n",
    "    beta_start  = args.beta \n",
    "    beta_end    = 3.0 \n",
    "    beta_step   = 0.1\n",
    "\n",
    "    for alpha in torch.arange(alpha_start, alpha_end, alpha_step):\n",
    "        alpha = alpha.item()\n",
    "        tmp_best_alpha  = None\n",
    "        tmp_best_beta   = None\n",
    "        tmp_best_recall = 0\n",
    "\n",
    "        early_stop = 0\n",
    "\n",
    "        for beta in torch.arange(beta_start, beta_end, beta_step):\n",
    "            beta = beta.item()\n",
    "            print(\"Alpha:\", alpha, \"Beta:\", beta)\n",
    "\n",
    "            counter = 0\n",
    "            recall = 0\n",
    "\n",
    "            while counter < total_query_num:\n",
    "                with h5py.File(file_path, 'r') as f:\n",
    "                    test_set = torch.tensor(f['test'][counter : counter+args.query_num], dtype=torch.float32).to(device)\n",
    "                    test_neighbors_id = f['neighbors'][counter : counter+args.query_num]\n",
    "\n",
    "                # print(\"Processed query from\", counter, \"to\", counter + test_set.shape[0] - 1)\n",
    "\n",
    "                if args.similarity == \"segmented_cosine\":\n",
    "                    result_id, average_similarity, average_difference, std_difference = do_compute_segmented_cosine(support_loader, test_set, topk=args.topk, scale=(1 / alpha), minimum=beta)\n",
    "                elif args.similarity == \"L1norm\":\n",
    "                    result_id, average_similarity, average_difference, std_difference = do_compute_L1norm(support_loader, test_set, topk=args.topk, clamp_ratio = beta)\n",
    "                average_similarity_array = []\n",
    "                average_difference_array = []\n",
    "                std_difference_array     = []\n",
    "\n",
    "                average_similarity_array.append(average_similarity)\n",
    "                average_difference_array.append(average_difference)\n",
    "                std_difference_array.append(std_difference)\n",
    "\n",
    "                for i in range(test_set.shape[0]):\n",
    "                    # print(\"Query ID:\", i, \"Query Label:\", test_neighbors_id[i])\n",
    "                    # print(\"Result ID:\", result_id[i])\n",
    "                    intersection = torch.isin(result_id[i], torch.tensor(test_neighbors_id[i], device=result_id.device))\n",
    "                    # print(\"Intersection:\", intersection.sum())\n",
    "                    recall += intersection.sum().item() / len(test_neighbors_id[i])\n",
    "\n",
    "                counter += args.query_num\n",
    "\n",
    "            average_similarity = torch.tensor(average_similarity_array, device=device)\n",
    "            total_average_similarity = torch.mean(average_similarity)\n",
    "            average_difference = torch.tensor(average_difference_array, device=device)\n",
    "            total_average_difference = torch.mean(average_difference)\n",
    "            std_difference = torch.tensor(std_difference_array, device=device)\n",
    "            total_std_difference =  torch.sqrt(torch.mean((std_difference**2) + (average_difference - total_average_difference)**2))\n",
    "\n",
    "            ave_recall = recall / total_query_num\n",
    "\n",
    "            print(\"Recall:\", ave_recall, \"with alpha:\", alpha, \"with beta:\", beta)\n",
    "            print(\"Difference:\", total_average_difference, total_std_difference)\n",
    "            print(\"Similarity:\", total_average_similarity)\n",
    "\n",
    "            if ave_recall >= tmp_best_recall:\n",
    "                early_stop = 0\n",
    "                tmp_best_recall = ave_recall\n",
    "                tmp_best_alpha = alpha\n",
    "                tmp_best_beta = beta\n",
    "                tmp_average_difference = total_average_difference\n",
    "                tmp_std_difference     = total_std_difference\n",
    "                tmp_average_similarity = total_average_similarity\n",
    "                # print(\"Temporal Best recall:\", tmp_best_recall, \"with alpha:\", tmp_best_alpha, \"with beta:\", tmp_best_beta)\n",
    "                if beta == beta_end:\n",
    "                    print(\"##############################################################\")\n",
    "                    print(\"Temporal Best recall:\", tmp_best_recall, \"with alpha:\", tmp_best_alpha, \"with beta:\", tmp_best_beta)\n",
    "                    print(\"Difference:\", tmp_average_difference, tmp_std_difference)\n",
    "                    print(\"Similarity:\", tmp_average_similarity)\n",
    "                    print(\"##############################################################\")\n",
    "                \n",
    "                last_time_recall = ave_recall\n",
    "\n",
    "            else:\n",
    "                if ave_recall < last_time_recall:   \n",
    "                    early_stop += 1\n",
    "                else:\n",
    "                    early_stop = 0\n",
    "                last_time_recall = ave_recall\n",
    "                if early_stop >= 2:\n",
    "                    print(\"##############################################################\")\n",
    "                    print(\"Temporal Best recall:\", tmp_best_recall, \"with alpha:\", tmp_best_alpha, \"with beta:\", tmp_best_beta)\n",
    "                    print(\"Difference:\", tmp_average_difference, tmp_std_difference)\n",
    "                    print(\"Similarity:\", tmp_average_similarity)\n",
    "                    print(\"##############################################################\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Early stop count:\", early_stop, \"with alpha:\", alpha, \"with beta:\", beta)\n",
    "            \n",
    "        if tmp_best_recall >= best_recall:\n",
    "            best_recall = tmp_best_recall\n",
    "            best_alpha = tmp_best_alpha\n",
    "            best_beta = tmp_best_beta\n",
    "            best_average_difference = tmp_average_difference\n",
    "            best_std_difference = tmp_std_difference\n",
    "            best_average_similarity = tmp_average_similarity\n",
    "        else:\n",
    "            print(\"##############################################################\")\n",
    "            print(\"Best recall:\", best_recall, \"with alpha:\", best_alpha, \"with beta:\", best_beta)\n",
    "            print(\"Difference:\", best_average_difference, best_std_difference)\n",
    "            print(\"Similarity:\", best_average_similarity)\n",
    "            print(\"##############################################################\")\n",
    "            break\n",
    "        print(\"##############################################################\")\n",
    "        print(\"Best recall:\", best_recall, \"with alpha:\", best_alpha, \"with beta:\", best_beta)\n",
    "        print(\"Difference:\", best_average_difference, best_std_difference)\n",
    "        print(\"Similarity:\", best_average_similarity)\n",
    "        print(\"##############################################################\")\n",
    "\n",
    "        if args.option != \"TLE\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ee012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution Block\n",
    "if __name__ == '__main__':\n",
    "    if args.find_best_recall:\n",
    "        find_best_recall()\n",
    "    else:\n",
    "        inference()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
