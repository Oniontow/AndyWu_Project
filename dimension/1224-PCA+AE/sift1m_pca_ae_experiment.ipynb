{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ca829f",
   "metadata": {},
   "source": [
    "# SIFT-1M Dimensionality Reduction Experiment: PCA -> Autoencoder\n",
    "\n",
    "This notebook implements a two-stage dimensionality reduction pipeline:\n",
    "1.  **PCA**: Reduce SIFT-1M data (128d) to $x$ dimensions, where $x \\in \\{16, 32, ..., 128\\}$.\n",
    "2.  **Autoencoder**: Reduce from $x$ dimensions to 64 dimensions.\n",
    "    *   Loss Function: Reconstruction Loss + 3 * Distance Loss.\n",
    "\n",
    "Finally, we evaluate Recall@100, Recall@500, and Recall@1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Constants\n",
    "SIFT_DIM = 128\n",
    "FINAL_DIM = 64\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50 # Reduced epochs for faster experimentation, can be increased\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64392632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "import shutil\n",
    "import socket\n",
    "\n",
    "def download_sift1m():\n",
    "    \"\"\"\n",
    "    Download SIFT1M dataset if not exists\n",
    "    \"\"\"\n",
    "    # Create data directory\n",
    "    if not os.path.exists('sift1m'):\n",
    "        os.makedirs('sift1m')\n",
    "    \n",
    "    files = [\n",
    "        \"sift_base.fvecs\",\n",
    "        \"sift_query.fvecs\",\n",
    "        \"sift_groundtruth.ivecs\"\n",
    "    ]\n",
    "    \n",
    "    # Check if files exist\n",
    "    all_exist = True\n",
    "    for filename in files:\n",
    "        if not os.path.exists(os.path.join('sift1m', filename)):\n",
    "            all_exist = False\n",
    "            break\n",
    "            \n",
    "    if all_exist:\n",
    "        print(\"All SIFT1M files exist.\")\n",
    "        return True\n",
    "        \n",
    "    print(\"Downloading SIFT1M dataset...\")\n",
    "    \n",
    "    tar_url = \"ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\"\n",
    "    tar_path = \"sift1m/sift.tar.gz\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Downloading from {tar_url}...\")\n",
    "        socket.setdefaulttimeout(30)\n",
    "        urllib.request.urlretrieve(tar_url, tar_path)\n",
    "        print(\"Download complete. Extracting...\")\n",
    "        \n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "            tar.extractall(path=\"sift1m\")\n",
    "            \n",
    "        # Move files from sift1m/sift/ to sift1m/\n",
    "        extracted_dir = os.path.join(\"sift1m\", \"sift\")\n",
    "        if os.path.exists(extracted_dir):\n",
    "            for filename in files:\n",
    "                src = os.path.join(extracted_dir, filename)\n",
    "                dst = os.path.join(\"sift1m\", filename)\n",
    "                if os.path.exists(src):\n",
    "                    if os.path.exists(dst):\n",
    "                        os.remove(dst)\n",
    "                    os.rename(src, dst)\n",
    "            # Cleanup\n",
    "            shutil.rmtree(extracted_dir)\n",
    "                \n",
    "        # Remove tar file\n",
    "        if os.path.exists(tar_path):\n",
    "            os.remove(tar_path)\n",
    "        print(\"Dataset ready.\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "        print(\"Please manually download sift.tar.gz from http://corpus-texmex.irisa.fr/ and extract to sift1m/ folder.\")\n",
    "        return False\n",
    "\n",
    "def read_fvecs(filename):\n",
    "    \"\"\"Read .fvecs file\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        d = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "        f.seek(0)\n",
    "        data = np.fromfile(f, dtype=np.float32)\n",
    "        data = data.reshape(-1, d + 1)\n",
    "        return data[:, 1:].copy()\n",
    "\n",
    "def read_ivecs(filename):\n",
    "    \"\"\"Read .ivecs file\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        d = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "        f.seek(0)\n",
    "        data = np.fromfile(f, dtype=np.int32)\n",
    "        data = data.reshape(-1, d + 1)\n",
    "        return data[:, 1:].copy()\n",
    "\n",
    "# Ensure data is present\n",
    "if not download_sift1m():\n",
    "    raise RuntimeError(\"Failed to download dataset and files are missing.\")\n",
    "\n",
    "# Load Data\n",
    "data_dir = 'sift1m'\n",
    "try:\n",
    "    print(\"Loading SIFT1M dataset...\")\n",
    "    base_vectors = read_fvecs(os.path.join(data_dir, 'sift_base.fvecs'))\n",
    "    query_vectors = read_fvecs(os.path.join(data_dir, 'sift_query.fvecs'))\n",
    "    ground_truth = read_ivecs(os.path.join(data_dir, 'sift_groundtruth.ivecs'))\n",
    "    print(f\"Base vectors: {base_vectors.shape}\")\n",
    "    print(f\"Query vectors: {query_vectors.shape}\")\n",
    "    print(f\"Ground truth: {ground_truth.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise # Stop execution if loading fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93744968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerDimensionQuantileQuantizer:\n",
    "    \"\"\"\n",
    "    Quantize to INT3 using per-dimension quantiles.\n",
    "    For each dimension, it calculates 7 thresholds (1/8, 2/8, ..., 7/8 quantiles)\n",
    "    from the training data, and maps values to bins -4 to 3.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.thresholds = None\n",
    "        self.device = DEVICE\n",
    "\n",
    "    def fit(self, data):\n",
    "        if isinstance(data, np.ndarray):\n",
    "            data = torch.from_numpy(data)\n",
    "        if data.device != self.device:\n",
    "            data = data.to(self.device)\n",
    "        \n",
    "        data = data.float()\n",
    "        N, D = data.shape\n",
    "        \n",
    "        # Calculate quantiles for each dimension\n",
    "        q_vals = torch.tensor([0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875], device=self.device)\n",
    "        \n",
    "        try:\n",
    "            self.thresholds = torch.quantile(data, q_vals, dim=0) # (7, D)\n",
    "        except RuntimeError:\n",
    "            if N > 100000:\n",
    "                step = N // 100000\n",
    "                sample = data[::step]\n",
    "                self.thresholds = torch.quantile(sample, q_vals, dim=0)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.thresholds is None:\n",
    "            raise ValueError(\"Quantizer not fitted\")\n",
    "            \n",
    "        if isinstance(data, np.ndarray):\n",
    "            data = torch.from_numpy(data)\n",
    "        if data.device != self.device:\n",
    "            data = data.to(self.device)\n",
    "            \n",
    "        data = data.float()\n",
    "        \n",
    "        comparison = data.unsqueeze(1) >= self.thresholds.unsqueeze(0)\n",
    "        rank = torch.sum(comparison, dim=1).to(torch.int8) # (N, D), values 0-7\n",
    "        \n",
    "        return rank - 4\n",
    "        \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "def apply_quantization(train_data, query_data):\n",
    "    quantizer = PerDimensionQuantileQuantizer()\n",
    "    train_q = quantizer.fit_transform(train_data)\n",
    "    query_q = quantizer.transform(query_data)\n",
    "    # Return as numpy for evaluation (or keep as tensor if evaluate_recall handles it)\n",
    "    # evaluate_recall expects numpy or tensor, but let's return numpy to be safe/consistent\n",
    "    return train_q.cpu().numpy(), query_q.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=64):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # Calculate hidden dimension: (input_dim + 64) / 2\n",
    "        hidden_dim = (input_dim + latent_dim) // 2\n",
    "        \n",
    "        # Encoder: Input -> Hidden -> Latent\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Decoder: Latent -> Hidden -> Input\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "def train_autoencoder(data, input_dim, latent_dim=64, epochs=50, batch_size=256, patience=5, distance_loss_weight=3.0):\n",
    "    \"\"\"\n",
    "    Train AutoEncoder with Reconstruction Loss + Distance Loss (1:3 ratio)\n",
    "    \"\"\"\n",
    "    model = AutoEncoder(input_dim, latent_dim).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion_recon = nn.MSELoss()\n",
    "    criterion_dist = nn.MSELoss()\n",
    "    \n",
    "    # Convert data to tensor\n",
    "    if isinstance(data, np.ndarray):\n",
    "        data_tensor = torch.FloatTensor(data)\n",
    "    else:\n",
    "        data_tensor = data\n",
    "        \n",
    "    # Create DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(data_tensor)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    history = {'loss': [], 'recon_loss': [], 'dist_loss': []}\n",
    "    \n",
    "    # Use tqdm for progress\n",
    "    pbar = tqdm(range(epochs), desc=f\"Training AE (Input: {input_dim})\", leave=False)\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        total_loss = 0\n",
    "        total_recon = 0\n",
    "        total_dist = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            batch_data = batch[0].to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            encoded, reconstructed = model(batch_data)\n",
    "            \n",
    "            # 1. Reconstruction Loss\n",
    "            recon_loss = criterion_recon(reconstructed, batch_data)\n",
    "            \n",
    "            # 2. Distance Preservation Loss\n",
    "            # Calculate pairwise distances in batch\n",
    "            # Input space distance\n",
    "            dist_input = torch.cdist(batch_data, batch_data, p=2)\n",
    "            # Latent space distance\n",
    "            dist_latent = torch.cdist(encoded, encoded, p=2)\n",
    "            \n",
    "            # Loss: MSE between distance matrices\n",
    "            dist_loss = criterion_dist(dist_latent, dist_input)\n",
    "            \n",
    "            # Total Loss = 1 * Recon + 3 * Distance\n",
    "            loss = recon_loss + distance_loss_weight * dist_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_recon += recon_loss.item()\n",
    "            total_dist += dist_loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "        avg_loss = total_loss / num_batches\n",
    "        avg_recon = total_recon / num_batches\n",
    "        avg_dist = total_dist / num_batches\n",
    "        \n",
    "        history['loss'].append(avg_loss)\n",
    "        history['recon_loss'].append(avg_recon)\n",
    "        history['dist_loss'].append(avg_dist)\n",
    "        \n",
    "        pbar.set_postfix({'Loss': f\"{avg_loss:.4f}\", 'Recon': f\"{avg_recon:.4f}\", 'Dist': f\"{avg_dist:.4f}\"})\n",
    "        \n",
    "        # Early Stopping\n",
    "        if avg_loss < best_loss - 1e-4:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "                \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recall(queries_encoded, database_encoded, ground_truth, k_values=[100, 500, 1000]):\n",
    "    \"\"\"\n",
    "    Calculate Recall@K.\n",
    "    Recall@K = (Number of relevant items in top K retrieved) / (Total number of relevant items)\n",
    "    For SIFT1M, ground_truth contains top 100 neighbors. So Total relevant = 100.\n",
    "    \"\"\"\n",
    "    # Calculate distances in reduced space\n",
    "    # Using CPU for distance calculation to avoid OOM on GPU if dataset is large, \n",
    "    # or use GPU in batches if needed. SIFT1M (1M vectors) might fit in GPU memory for distance calc if careful.\n",
    "    # Let's use sklearn pairwise_distances (CPU) or faiss if available. \n",
    "    # Since we imported pairwise_distances, we'll use that or a batched GPU approach.\n",
    "    # Given 1M vectors, pairwise_distances(10k queries, 1M db) is large (10^10 floats = 40GB).\n",
    "    # We must batch.\n",
    "    \n",
    "    print(\"Calculating distances and recall...\")\n",
    "    num_queries = queries_encoded.shape[0]\n",
    "    recalls = {k: [] for k in k_values}\n",
    "    \n",
    "    # Ensure data is on CPU for simple processing or GPU for speed\n",
    "    # Let's use a batched GPU approach for speed\n",
    "    queries_t = torch.FloatTensor(queries_encoded).to(DEVICE)\n",
    "    database_t = torch.FloatTensor(database_encoded).to(DEVICE)\n",
    "    \n",
    "    batch_size = 100\n",
    "    \n",
    "    for i in range(0, num_queries, batch_size):\n",
    "        end = min(i + batch_size, num_queries)\n",
    "        q_batch = queries_t[i:end]\n",
    "        \n",
    "        # Calculate distance to all database vectors\n",
    "        # dists: (batch_size, 1M)\n",
    "        # To save memory, we can iterate over database too, but let's try full DB if it fits\n",
    "        # 1M * 64 floats is small (256MB). \n",
    "        # q_batch (100 * 64).\n",
    "        # cdist output (100 * 1M) = 100M floats = 400MB. This fits easily in GPU.\n",
    "        \n",
    "        dists = torch.cdist(q_batch, database_t)\n",
    "        \n",
    "        # Get top max_k indices\n",
    "        max_k = max(k_values)\n",
    "        # topk returns largest, we want smallest distance. So use negative distance or sort.\n",
    "        # topk is faster than sort.\n",
    "        _, indices = torch.topk(dists, k=max_k, dim=1, largest=False)\n",
    "        \n",
    "        indices = indices.cpu().numpy()\n",
    "        \n",
    "        for j in range(len(indices)):\n",
    "            gt = ground_truth[i + j] # Top 100 GT\n",
    "            # For SIFT1M, gt has 100 neighbors.\n",
    "            gt_set = set(gt)\n",
    "            \n",
    "            retrieved_indices = indices[j]\n",
    "            \n",
    "            for k in k_values:\n",
    "                retrieved_k = set(retrieved_indices[:k])\n",
    "                intersection = len(gt_set.intersection(retrieved_k))\n",
    "                recall = intersection / len(gt_set) # usually 100\n",
    "                recalls[k].append(recall)\n",
    "                \n",
    "    # Average recall\n",
    "    avg_recalls = {k: np.mean(v) for k, v in recalls.items()}\n",
    "    return avg_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Experiment Loop\n",
    "x_values = range(16, 129, 16) # 16, 32, ..., 128\n",
    "results = []\n",
    "\n",
    "print(\"=== Baseline: Autoencoder Only (128 -> 64) ===\")\n",
    "# Train AE on raw data (128 dim)\n",
    "ae_only_train_data = base_vectors[:100000]\n",
    "ae_only_model, _ = train_autoencoder(\n",
    "    ae_only_train_data, \n",
    "    input_dim=128, \n",
    "    latent_dim=64, \n",
    "    epochs=EPOCHS, \n",
    "    distance_loss_weight=3.0\n",
    ")\n",
    "\n",
    "ae_only_model.eval()\n",
    "with torch.no_grad():\n",
    "    def encode_in_batches(data, model, batch_size=10000):\n",
    "        encoded_list = []\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = torch.FloatTensor(data[i:i+batch_size]).to(DEVICE)\n",
    "            encoded = model.encode(batch)\n",
    "            encoded_list.append(encoded.cpu().numpy())\n",
    "        return np.vstack(encoded_list)\n",
    "        \n",
    "    base_ae_only = encode_in_batches(base_vectors, ae_only_model)\n",
    "    query_ae_only = encode_in_batches(query_vectors, ae_only_model)\n",
    "\n",
    "# Quantize AE Only\n",
    "print(\"Quantizing AE Only results...\")\n",
    "base_ae_only_q, query_ae_only_q = apply_quantization(base_ae_only, query_ae_only)\n",
    "\n",
    "# Evaluate AE Only\n",
    "recalls_ae_only = evaluate_recall(query_ae_only_q, base_ae_only_q, ground_truth, k_values=[100, 500, 1000])\n",
    "print(f\"AE Only Results: {recalls_ae_only}\")\n",
    "\n",
    "\n",
    "print(f\"\\nStarting PCA experiment for x values: {list(x_values)}\")\n",
    "\n",
    "for x in x_values:\n",
    "    print(f\"\\n=== Processing x = {x} ===\")\n",
    "    \n",
    "    # 1. PCA Reduction\n",
    "    print(f\"Step 1: PCA Reduction to {x} dimensions...\")\n",
    "    pca = PCA(n_components=x, whiten=True)\n",
    "    pca_train_data = base_vectors[:100000] \n",
    "    pca.fit(pca_train_data)\n",
    "    \n",
    "    base_pca = pca.transform(base_vectors)\n",
    "    query_pca = pca.transform(query_vectors)\n",
    "    \n",
    "    # Baseline: PCA Only -> Quantize -> Recall\n",
    "    print(f\"Evaluating PCA Only ({x} dim)...\")\n",
    "    base_pca_q, query_pca_q = apply_quantization(base_pca, query_pca)\n",
    "    recalls_pca_only = evaluate_recall(query_pca_q, base_pca_q, ground_truth, k_values=[100, 500, 1000])\n",
    "    print(f\"PCA Only ({x}) Results: {recalls_pca_only}\")\n",
    "    \n",
    "    # 2. Autoencoder Training (PCA -> AE)\n",
    "    print(f\"Step 2: Training Autoencoder ({x} -> {FINAL_DIM})...\")\n",
    "    ae_train_data = base_pca[:100000]\n",
    "    \n",
    "    ae_model, history = train_autoencoder(\n",
    "        ae_train_data, \n",
    "        input_dim=x, \n",
    "        latent_dim=FINAL_DIM, \n",
    "        epochs=EPOCHS, \n",
    "        distance_loss_weight=3.0\n",
    "    )\n",
    "    \n",
    "    # 3. Encoding\n",
    "    print(\"Step 3: Encoding data...\")\n",
    "    ae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        base_encoded = encode_in_batches(base_pca, ae_model)\n",
    "        query_encoded = encode_in_batches(query_pca, ae_model)\n",
    "        \n",
    "    # Quantize PCA -> AE\n",
    "    print(\"Quantizing PCA -> AE results...\")\n",
    "    base_encoded_q, query_encoded_q = apply_quantization(base_encoded, query_encoded)\n",
    "        \n",
    "    # 4. Evaluation\n",
    "    print(\"Step 4: Evaluating Recall...\")\n",
    "    recalls_pca_ae = evaluate_recall(query_encoded_q, base_encoded_q, ground_truth, k_values=[100, 500, 1000])\n",
    "    \n",
    "    print(f\"PCA -> AE ({x}->64) Results: {recalls_pca_ae}\")\n",
    "    \n",
    "    results.append({\n",
    "        'x': x,\n",
    "        # PCA -> AE\n",
    "        'pca_ae_recall@100': recalls_pca_ae[100],\n",
    "        'pca_ae_recall@500': recalls_pca_ae[500],\n",
    "        'pca_ae_recall@1000': recalls_pca_ae[1000],\n",
    "        # PCA Only\n",
    "        'pca_only_recall@100': recalls_pca_only[100],\n",
    "        'pca_only_recall@500': recalls_pca_only[500],\n",
    "        'pca_only_recall@1000': recalls_pca_only[1000],\n",
    "        # AE Only (Constant)\n",
    "        'ae_only_recall@100': recalls_ae_only[100],\n",
    "        'ae_only_recall@500': recalls_ae_only[500],\n",
    "        'ae_only_recall@1000': recalls_ae_only[1000]\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(df_results)\n",
    "df_results.to_csv('sift1m_pca_ae_comparison_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# Plot Recall@100\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_results['x'], df_results['pca_ae_recall@100'], marker='o', label='PCA(x) -> AE(64)')\n",
    "plt.plot(df_results['x'], df_results['pca_only_recall@100'], marker='s', label='PCA(x) Only')\n",
    "plt.axhline(y=df_results['ae_only_recall@100'][0], color='r', linestyle='--', label='AE(128->64) Only')\n",
    "\n",
    "plt.title('Recall@100 Comparison (Quantized INT3)')\n",
    "plt.xlabel('PCA Dimension (x)')\n",
    "plt.ylabel('Recall@100')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(list(x_values))\n",
    "plt.savefig('recall_at_100.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot Recall@500\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_results['x'], df_results['pca_ae_recall@500'], marker='o', label='PCA(x) -> AE(64)')\n",
    "plt.plot(df_results['x'], df_results['pca_only_recall@500'], marker='s', label='PCA(x) Only')\n",
    "plt.axhline(y=df_results['ae_only_recall@500'][0], color='r', linestyle='--', label='AE(128->64) Only')\n",
    "\n",
    "plt.title('Recall@500 Comparison (Quantized INT3)')\n",
    "plt.xlabel('PCA Dimension (x)')\n",
    "plt.ylabel('Recall@500')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(list(x_values))\n",
    "plt.savefig('recall_at_500.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot Recall@1000\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_results['x'], df_results['pca_ae_recall@1000'], marker='o', label='PCA(x) -> AE(64)')\n",
    "plt.plot(df_results['x'], df_results['pca_only_recall@1000'], marker='s', label='PCA(x) Only')\n",
    "plt.axhline(y=df_results['ae_only_recall@1000'][0], color='r', linestyle='--', label='AE(128->64) Only')\n",
    "\n",
    "plt.title('Recall@1000 Comparison (Quantized INT3)')\n",
    "plt.xlabel('PCA Dimension (x)')\n",
    "plt.ylabel('Recall@1000')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(list(x_values))\n",
    "plt.savefig('recall_at_1000.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
